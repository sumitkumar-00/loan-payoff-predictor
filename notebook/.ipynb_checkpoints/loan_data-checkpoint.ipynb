{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction:\n",
    "publicly available data from LendingClub.com. Lending Club connects people who need money (borrowers) with people who have money (investors). Hopefully, as an investor you would want to invest in people who showed a profile of having a high probability of paying you back.\n",
    "\n",
    "We will use lending data from 2007-2010 and be trying to classify and predict whether or not the borrower paid back their loan in full. You can download the data from here.\n",
    "\n",
    "Here are what the columns represent:\n",
    "\n",
    "1. credit.policy: 1 if the customer meets the credit underwriting criteria of LendingClub.com, and 0 otherwise.\n",
    "2. purpose: The purpose of the loan (takes values \"creditcard\", \"debtconsolidation\", \"educational\", \"majorpurchase\", \"smallbusiness\", and \"all_other\").\n",
    "3. int.rate: The interest rate of the loan, as a proportion (a rate of 11% would be stored as 0.11). Borrowers judged by LendingClub.com to be more risky are assigned higher interest rates.\n",
    "4. installment: The monthly installments owed by the borrower if the loan is funded.\n",
    "5. log.annual.inc: The natural log of the self-reported annual income of the borrower.\n",
    "6. dti: The debt-to-income ratio of the borrower (amount of debt divided by annual income).\n",
    "7. fico: The FICO credit score of the borrower.\n",
    "8. days.with.cr.line: The number of days the borrower has had a credit line.\n",
    "9. revol.bal: The borrower's revolving balance (amount unpaid at the end of the credit card billing cycle).\n",
    "10. revol.util: The borrower's revolving line utilization rate (the amount of the credit line used relative to total credit available).\n",
    "11. inq.last.6mths: The borrower's number of inquiries by creditors in the last 6 months.\n",
    "12. delinq.2yrs: The number of times the borrower had been 30+ days past due on a payment in the past 2 years.\n",
    "13. pub.rec: The borrower's number of derogatory public records (bankruptcy filings, tax liens, or judgments)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives:\n",
    "1. Get insights from the data using exploratory data analysis\n",
    "2. Build a Machine Learning model to predict if a loan would be paid in full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'custom_transformer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0104e08cfaff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../util'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcustom_transformer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNumericalFeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCategoricalFeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'custom_transformer'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "#Modeling\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, classification_report, make_scorer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from xgboost import XGBClassifier\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld = pd.read_csv(\"../data/loan_data.csv\")\n",
    "print(\"Number of observations in the dataset: \" + str(ld.shape[0]))\n",
    "print(\"Number of columns in the dataset: \" + str(ld.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data:\n",
    "#### In this step we are going to check if we have any missing values and if any data type conversion might be necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld.isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Great! We do not have any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All of the features are numeric except purpose which is string. During modeling we will convert it to numeric using OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld_purpose = ld.groupby(['purpose'])['not.fully.paid'].value_counts().unstack()\n",
    "ld_purpose = ld_purpose.reset_index()\n",
    "ld_purpose.columns = ['purpose','paid','not_fully_paid']\n",
    "ld_purpose.index.rename('',inplace=True)\n",
    "ld_purpose['%paid']=ld_purpose.apply(lambda x: round((x.paid/(x.paid+x.not_fully_paid))*100, 2), axis=1)\n",
    "ld_purpose['%not_fully_paid']=ld_purpose.apply(lambda x: round((x.not_fully_paid/(x.paid+x.not_fully_paid))*100, 2), axis=1)\n",
    "ld_purpose['%of_all_loans']=round((ld_purpose.paid + ld_purpose.not_fully_paid)/ld.shape[0], 2)\n",
    "ld_purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "x = np.arange(len(ld_purpose.purpose))\n",
    "width = 0.35\n",
    "rects = ax.bar(x, ld_purpose['%of_all_loans'], width=width)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(ld_purpose.purpose, rotation=90)\n",
    "ax.set_ylim([0, 0.45])\n",
    "ax.set_ylabel(\"Percentage of all loans\")\n",
    "ax.set_title(\"Percentage and absolute count of loans across purposes\")\n",
    "\n",
    "labels = list(ld_purpose.paid + ld_purpose.not_fully_paid)\n",
    "\n",
    "for rect, label in zip(rects, labels):\n",
    "    y = rect.get_height()\n",
    "    x = rect.get_x()\n",
    "    ax.text(x, y + 0.01, label)\n",
    "plt.savefig(\"../static/purpose.png\", dpi=1200)    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Debt consolidation loans present largest share(41%) of the approved loans at lendingtree\n",
    "2. Educational loans present smallest share(4%) of the approved loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar_charts(df, col):\n",
    "    labels = df[col]\n",
    "    paid = df['%paid']\n",
    "    not_fully_paid = df['%not_fully_paid']\n",
    "    \n",
    "    x = np.arange(len(df.purpose))\n",
    "    width = 0.35\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10,7))\n",
    "    \n",
    "    rect1 = ax.bar(x-width/2, paid, width=width, label='Paid')\n",
    "    rect2 = ax.bar(x+width/2, not_fully_paid, width=width, label='Not Fully Paid')\n",
    "    \n",
    "    ax.set_title(\"Distribution of paid/not fully paid loans across purposes\")\n",
    "    ax.set_ylabel(\"Percentage\")\n",
    "    ax.set_ylim([0,93])\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels, rotation=90)\n",
    "    \n",
    "    ax.legend(loc = 'upper right')\n",
    "    \n",
    "    ax.bar_label(rect1, padding=3)\n",
    "    ax.bar_label(rect2, padding=3)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.savefig(\"../static/purpose_paid_not_paid.png\", dpi=1200)\n",
    "    plt.show()\n",
    "\n",
    "plot_bar_charts(ld_purpose, 'purpose')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Small Business loans have the highest percentage of not fully paid loans at 28%\n",
    "2. Major purchases have the lowest percentage of not fully paid loans at 11%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_box_plot(colname, label, df):\n",
    "#     paid = df.loc[df['not.fully.paid']==0, colname]\n",
    "#     not_fully_paid = df.loc[df['not.fully.paid']==1, colname]\n",
    "    \n",
    "#     fig, ax = plt.subplots(figsize=(10,6))\n",
    "#     bp1 = ax.boxplot(paid, patch_artist=True, positions=[1], boxprops = dict(facecolor='green', color='green'))\n",
    "#     bp2 = ax.boxplot(not_fully_paid, positions=[2], patch_artist=True, boxprops=dict(facecolor='red', color='red'))\n",
    "\n",
    "#     ax.set_ylabel(label)\n",
    "#     ax.set_xticklabels(['Paid','Not Fully Paid'])\n",
    "    \n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld_column_key = {'purpose':'Purpose', 'int.rate':'Interest Rate of Loan', 'installment':'Monthly Installment', 'log.annual.inc':'Natural Log of Annual Income', 'dti':'Debt to Income Ratio', \\\n",
    "                 'fico':'Fico Credit Score', 'days.with.cr.line':'Number of Days with a Credit Line', 'revol.bal':'Revolving Credit Line Balance', 'revol.util':'Revolving Credit Line Utilization',\\\n",
    "                 'inq.last.6mths':'Number of Inquiries in last 6 Months', 'delinq.2yrs':'Number of Deliquencies in Last 2 yrs.', 'pub.rec':'Number of Derogatory Public Records'}\n",
    "\n",
    "#credit_policy dict\n",
    "credit_policy_dict= {0:'Underwriting criteria did not meet', 1:'Underwriting criteria met'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_box_plot(colname, label, df, ld_column_key=ld_column_key):\n",
    "    fig, ax = plt.subplots(4, 3, figsize=(18,14))\n",
    "    i = 0\n",
    "    j = 0\n",
    "    \n",
    "    for col in colname:\n",
    "        paid = df.loc[df['not.fully.paid']==0, col]    \n",
    "#         quantiles = paid.quantile([0.25, 0.50, 0.75]).values\n",
    "        bp1 = ax[i,j].boxplot(paid, patch_artist=True, positions=[1], boxprops = dict(facecolor='green', color='green'))\n",
    "#         ax[i,j].text(1, quantiles[0], s = str(quantiles[0]))\n",
    "#         ax[i,j].text(1, quantiles[1], s = str(quantiles[1]))\n",
    "#         ax[i,j].text(1, quantiles[2], s = str(quantiles[2]))\n",
    "        \n",
    "        not_fully_paid = df.loc[df['not.fully.paid']==1, col]\n",
    "        bp2 = ax[i,j].boxplot(not_fully_paid, positions=[2], patch_artist=True, boxprops=dict(facecolor='red', color='red'))\n",
    "\n",
    "        ax[i, j].set_ylabel(ld_column_key.get(col))\n",
    "        ax[i, j].set_xticklabels(['Paid','Not Fully Paid'])\n",
    "#         ax[i, j].grid(axis='y')\n",
    "        \n",
    "        j = j + 1\n",
    "        if j == 3:\n",
    "            i = i +1\n",
    "            j = 0\n",
    "    \n",
    "    fig.delaxes(ax=ax[3,2])\n",
    "    plt.savefig(\"../static/box_plot.png\", dpi=800, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = ['int.rate','installment','log.annual.inc','dti','fico','days.with.cr.line', 'revol.bal','revol.util', 'inq.last.6mths','delinq.2yrs','pub.rec']\n",
    "make_box_plot(colnames, 'label', ld)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We see that full loan payment is associated with slightly\n",
    "    1. lower interest rate \n",
    "    2. higher FICO credit score\n",
    "    3. lower credit line utilization\n",
    "    4. lower Debt to Income ratio\n",
    "2. It is worth noting that the median values of the aforementioned features do not differ by much for the loans that were not paid in full\n",
    "3. We see quite a few outlier associated with most of the features. We will take care of them we normalize our training data during modeling\n",
    "4. These boxplots show that median values of the features are very close for paid and unpaid loans. I will try histograms to see if they reveal something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paid_patch = mpatches.Patch(color='g', label='Paid')\n",
    "not_fully_paid_patch = mpatches.Patch(color='r', label='Not Fully Paid')\n",
    "\n",
    "fig, ax = plt.subplots(3,4, figsize=(18,12))\n",
    "i, j = 0 ,0\n",
    "\n",
    "for col in ['int.rate','installment','log.annual.inc','dti','fico','days.with.cr.line', 'revol.bal','revol.util', 'inq.last.6mths','delinq.2yrs','pub.rec']:\n",
    "    ax[i, j].hist(ld.loc[ld['not.fully.paid']==0, col], bins=15, color='g', histtype='step');\n",
    "    ax[i, j].hist(ld.loc[ld['not.fully.paid']==1, col], bins=15, alpha=0.5, color='r', histtype='step');\n",
    "    ax[i, j].set_title(ld_column_key.get(col))\n",
    "    \n",
    "    j = j + 1\n",
    "    if j==4:\n",
    "        i = i + 1\n",
    "        j =0\n",
    "\n",
    "    fig.tight_layout()\n",
    "fig.legend(handles = [paid_patch, not_fully_paid_patch], bbox_to_anchor=(0.1, 1, 0.8, .8), loc='lower left',\n",
    "           ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "\n",
    "fig.delaxes(ax=ax[2,3])\n",
    "plt.savefig(\"../static/histogram.png\", dpi=800, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of the features are very similar for paid and unpaid loans. It would be interesting to see how a model performs with this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld['credit.policy'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that some loans (1868) were approved even when the customer did not meet the credit underwriting criteria. Not sure why a loan would be approved if credit criteria was not met ?? Let's see what happened to those loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar_chart_binary_col(df, col):\n",
    "    df = ld.groupby([col])['not.fully.paid'].value_counts().unstack()    \n",
    "    df = df.reset_index()\n",
    "    df.columns = [col,'paid','not_fully_paid']\n",
    "    df.index.rename('',inplace=True)\n",
    "    df['%paid']=ld_purpose.apply(lambda x: round((x.paid/(x.paid+x.not_fully_paid))*100, 2), axis=1)\n",
    "    df['%not_fully_paid']=ld_purpose.apply(lambda x: round((x.not_fully_paid/(x.paid+x.not_fully_paid))*100, 2), axis=1)    \n",
    "    \n",
    "    #plot bar chart\n",
    "    labels = df[col].map(credit_policy_dict)\n",
    "    paid = df['%paid']\n",
    "    not_fully_paid = df['%not_fully_paid']\n",
    "    \n",
    "    x = np.arange(len(labels))\n",
    "    width = 0.35\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10,7))\n",
    "    \n",
    "    \n",
    "    rect1 = ax.bar(x - width/2, paid, width=width, label='Paid')\n",
    "    rect2 = ax.bar(x + width/2, not_fully_paid, width=width, label=\"Not Fully Paid\")\n",
    "    \n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels)\n",
    "    \n",
    "    ax.bar_label(rect1, padding=3)\n",
    "    ax.bar_label(rect2, padding=3)\n",
    "    \n",
    "    ax.set_title(col)\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.savefig('../static/credit_policy.png', dpi=1200)\n",
    "    plt.show()\n",
    "    \n",
    "plot_bar_chart_binary_col(ld, 'credit.policy')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credit underwriting criteria does not appear to be making a big difference here. 88% of the loans where paid when credit criteria was met and 83% of loans were paid when criteria was not met. A mere difference of 5%. We do not have the loan amount but we do have the installment. We might need to check if \n",
    "the installment amount is low for approved loans when credit criteria was not met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "installment = ld.groupby(['credit.policy']).agg(avg_installment=('installment','median')).reset_index()\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "x = installment['credit.policy']\n",
    "labels = installment['credit.policy'].map(credit_policy_dict)\n",
    "rect = ax.bar(x, installment.avg_installment)\n",
    "ax.set_xticks(x)\n",
    "ax.bar_label(rect, padding=1)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_ylabel(\"Median Installment\")\n",
    "ax.set_title(\"Underwriting Criteria and Installment\")\n",
    "plt.savefig(\"../static/installment.png\", dpi=1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Median installment amount for customers who did not meet credit criteria is about 14% lower than that of customers who met the criteria. Installment amount could be lower or higher depending upon the length and amount of the loan but we do not have that information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_rate = ld.groupby(['purpose']).agg(avg_int_rate=('int.rate','median'))\n",
    "x = np.arange(int_rate.shape[0])\n",
    "labels = int_rate.index\n",
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "rect = ax.bar(x, int_rate.avg_int_rate)\n",
    "ax.set_xticks(x)\n",
    "ax.bar_label(rect, padding=1)\n",
    "ax.set_xticklabels(labels, rotation=45)\n",
    "ax.set_ylabel(\"Median Interest Rate\")\n",
    "ax.set_title(\"Loan Purpose and Interest Rate\")\n",
    "plt.savefig(\"../static/int_rate.png\", dpi=1200, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Median interest rate was highest at 0.1379 for small business loans\n",
    "2. Major purchase loans had the lowest interest rate at 0.1158"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(ld.corr(), annot=True, fmt='.2f', cmap='BuGn')\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.savefig(\"../static/correlation.png\", dpi=1200, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interest rate and Fico score show the highest correlation(-ve) of -0.71 meaning customers with high fico score get lower interest rate on their loan. Interest rate is also positively correlated with revolving credit line utilization. Higher utilization means high interest rate. Some other sets of features show some correlation as well:\n",
    "1. Inquiry in last 6 months and customer meeting credit underwriting criteria are negatively correlated(-0.54): Less number of inquiries results in higher chances of meeting credit criteria\n",
    "2. Revolving utlization and Fico score are negatively correlated (-0.54): Low credit utilization results in higher FICO score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA Summary:\n",
    "\n",
    "1. Debt consolidation loans present largest share(41%) of the approved loans at lendingtree\n",
    "2. Educational loans present smallest share(4%) of the approved loans\n",
    "3. Small Business loans have the highest percentage of not fully paid loans at 28%\n",
    "4. Major purchases have the lowest percentage of not fully paid loans at 11%\n",
    "5. Not fully paid loans have slightly higher interest rate, lower FICO score, higher credit line utilization and higher debt to income ratio compared to paid loans. However, the median values don't differ by much in paid and not fully paid groups.\n",
    "6. 19.5% (1868) of the 9578 loans were approved for customers who did not meet company's credit underwriting criteria. 88% of the loans that were approved to customers meeting credit underwriting criteria paid off completely whereas 83% of the loans were completely paid off by the customers who did not meet the credit underwriting criteria. \n",
    "7. Median installment amount for customers who did not meet credit criteria is about 14% lower than that of customers who met the criteria. Installment amount could be lower or higher depending upon the length and amount of the loan but we do not have that information\n",
    "8. Median interest rate was highest at 0.1379 for small business loans\n",
    "9. Major purchase loans had the lowest interest rate at 0.1158"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is very important to check if we have a balanced dataset before we build a classification model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld.groupby('not.fully.paid').dti.count()/ld.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...And we have an imbalanced dataset. 84% of the loans were fully paid while 16% were not fully paid. It is easy to build a model that will always predict that a loan will be paid in full and it will still be correct 84% of the time i.e. accuracy of 84%. Accuracy is not the right metric to use here because we want to be able to correctly predict when a loan will be paid in full and when not paid in full. Some business input/knowledge is needed to strike a balance between False Positives and False Negatives. There are a couple of choices here:\n",
    "1. After splitting training and test data, we can oversample the under represented class i.e. loans that were not fully paid in our case to have a balanced dataset\n",
    "2. Another option is to use AUC (Area under curve) as a measure of performance for the model.\n",
    "\n",
    "I will be using AUC for my models. Here are some of the definitions related to AUC\n",
    "\n",
    "* FP: False Postive -> Incorrectly predicted  as positive\n",
    "* TP: True Positive -> Correctly predicted as positive\n",
    "* FN: False Negative -> Incorrectly predicted in negative\n",
    "* TN: True Negative -> Correctly predicted as negative\n",
    "$$FPR = FP/(FP+TN)$$\n",
    "$$TPR = TP/(TP+FN)$$\n",
    "AUC is a plot between FPR and TPR. The higher the area under curve (AUC) the model is a better classifier to distinguish between classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build two classes by extending BaseEstimator and TransformerMixing classes from sklearn packages. These will create two sets of features, one with numerical feature and other one with categorical features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X = X.select_dtypes(include='object')\n",
    "        return X\n",
    "    \n",
    "    \n",
    "class NumericalFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X = X.select_dtypes(include=np.number)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=7\n",
    "\n",
    "X = ld.drop(['not.fully.paid'], axis=1)\n",
    "y = ld['not.fully.paid'].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=random_state, stratify=y)\n",
    "\n",
    "X_train = X_train.copy()\n",
    "X_test = X_test.copy()\n",
    "y_train = y_train.copy()\n",
    "y_test = y_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just make sure that training set got all possible values of purpose. The model would not work if test data contained new value of purpose that it not trained on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.purpose.nunique())\n",
    "print(ld.purpose.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_numerical = Pipeline(steps=\n",
    "                                  [('numerical_features', NumericalFeatures()),\n",
    "                                   ('standard_scaler', StandardScaler())\n",
    "                                   ])\n",
    "\n",
    "pipeline_categorical = Pipeline(steps=\n",
    "                                    [('categorical_features', CategoricalFeatures()),\n",
    "                                     ('OneHotEncoder', OneHotEncoder())\n",
    "                                     ]\n",
    "                                    )\n",
    "pipeline_preprocessing = FeatureUnion(\n",
    "        [('numerical', pipeline_numerical),\n",
    "         ('categorical', pipeline_categorical)\n",
    "         ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "random_state = 7\n",
    "def check_model_accuracy(name, model, param_grid):\n",
    "    pipeline = Pipeline(steps=\n",
    "                       [\n",
    "                        ('preprocessing',pipeline_preprocessing),\n",
    "                        (model[0], model[1])   \n",
    "                       ]\n",
    "                       )\n",
    "    gs = GridSearchCV(estimator=pipeline, param_grid=param_grid, scoring='roc_auc', cv = 3, verbose=0, n_jobs=-1, error_score='raise')\n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    y_prob = gs.predict_proba(X_test)[:,1]    \n",
    "    auc_score = roc_auc_score(y_test, y_prob)\n",
    "    results.append([name, gs, auc_score])\n",
    "    print(name + \" AUC score is \" + str(auc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ('rf', RandomForestClassifier())\n",
    "param_grid = {\n",
    "              'rf__criterion' : ['gini','entropy'],\n",
    "              'rf__random_state' : [random_state] ,\n",
    "              'rf__n_estimators' : range(100,1000,100),\n",
    "              'rf__max_depth': range(2,8,2)\n",
    "}\n",
    "check_model_accuracy('RandomForest', model, param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = (\"knn\", KNeighborsClassifier())\n",
    "param_grid = {\n",
    "              'knn__n_neighbors':range(10,100, 5),\n",
    "              'knn__p':range(1,3)\n",
    "}\n",
    "check_model_accuracy('KNN', model, param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ('sgd',SGDClassifier())\n",
    "param_grid = {\n",
    "             'sgd__loss':['hinge','log','perceptron'],\n",
    "             'sgd__random_state':[random_state],\n",
    "             'sgd__penalty': ['l1','l2','elasticnet'],\n",
    "             'sgd__alpha': np.linspace(0.0001,1, 100)\n",
    "}\n",
    "check_model_accuracy('SGDClassifier', model, param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ('GB', GradientBoostingClassifier())\n",
    "param_grid = {\n",
    "              'GB__learning_rate':np.linspace(0.1,1,25),\n",
    "              'GB__max_depth':[3,4,5],\n",
    "              'GB__random_state':[random_state]\n",
    "}\n",
    "check_model_accuracy('GradientBoosting', model, param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ('LR',LogisticRegression())\n",
    "param_grid = {\n",
    "              'LR__random_state':[random_state],\n",
    "              'LR__C': np.linspace(0.001, 5, 100)              \n",
    "}\n",
    "check_model_accuracy('LogisticRegression', model, param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ('XGB', XGBClassifier())\n",
    "param_grid = {\n",
    "              'XGB__learning_rate':np.linspace(0.01, 1, 50)\n",
    "}\n",
    "check_model_accuracy('XGBClassifier', model, param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_score = pd.DataFrame([[r[0],r[2]] for r in results], columns=['model','auc_score'])\n",
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "x = np.arange(model_score.shape[0])\n",
    "rects = plt.bar(x, model_score.auc_score)\n",
    "ax.bar_label(rects)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(model_score.model, rotation=90)\n",
    "ax.set_yticks([])\n",
    "ax.set_ylabel(\"AUC\")\n",
    "ax.set_title(\"Test Scores\")\n",
    "plt.savefig(\"../static/results.png\", dpi=1200, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* All of the models are performing almost equally\n",
    "* LogisticRegression classification resulted in highest AUC score 0.69\n",
    "* AUC score between 0.6 and 0.7 is generally considered a fair score whereas AUC above 0.9 is considered outstanding\n",
    "* We can save the LogisticRegressionClassifier as pickled file and use it in an app for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4f18e1e6a6dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "results[-2][1].best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(results[-2][1],'../model/loan_data.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
